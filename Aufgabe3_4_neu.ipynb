{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 3 & 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementierung der gemischten BasicPRM- und GaussPRM-Verfahren "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Vermischung der beiden Verfahren wurden in den Dateien 'sampling_classes.py' und 'sampling_algorithms.py' umgesetzt.\n",
    "In diesem Notebook findet lediglich das Benchmark statt, um das reine BasicPRM- mit dem gemischten Verfahren zu vergleichen.\n",
    "Die Problemlösung für Aufgabe 3 ist somit in der Datei 'sampling_class.py' in der Klasse 'BasicGaussianPRM' vorhanden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"templates\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPPerfMonitor import IPPerfMonitor\n",
    "import IPBasicPRM\n",
    "import IPVISBasicPRM\n",
    "\n",
    "import IPBasicGaussian\n",
    "from sampling_classes import BasicGaussianPRM\n",
    "from scipy.spatial.distance import euclidean, cityblock\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konfiguration der Testumgebungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es werden jeweils 2 verschiedene Konfigurationen der beiden Verfahren getestet mit jeweils 200 und 400 Knoten insgesamt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plannerFactory = dict()\n",
    "\n",
    "basicConfig = dict()\n",
    "basicConfig[\"radius\"] = 3\n",
    "basicConfig[\"numNodes\"] = 200\n",
    "plannerFactory[\"basePRM_200\"] = [IPBasicPRM.BasicPRM, basicConfig, IPVISBasicPRM.basicPRMVisualize]\n",
    "\n",
    "basicConfig2 = dict()\n",
    "basicConfig2[\"radius\"] = 3\n",
    "basicConfig2[\"numNodes\"] = 400\n",
    "plannerFactory[\"basePRM2_400\"] = [IPBasicPRM.BasicPRM, basicConfig2, IPVISBasicPRM.basicPRMVisualize]\n",
    "\n",
    "\n",
    "\n",
    "configBasicGauss = dict()\n",
    "configBasicGauss[\"radius\"] = 3\n",
    "configBasicGauss[\"numNodesBasic\"] = 125\n",
    "configBasicGauss[\"numNodesGauss\"] = 75\n",
    "configBasicGauss[\"method\"] = 'simple'\n",
    "plannerFactory[\"BasicGauss_200\"] = [BasicGaussianPRM, configBasicGauss, IPVISBasicPRM.basicGaussPRMVisualize]\n",
    "\n",
    "configBasicGauss = dict()\n",
    "configBasicGauss[\"radius\"] = 3\n",
    "configBasicGauss[\"numNodesBasic\"] = 275\n",
    "configBasicGauss[\"numNodesGauss\"] = 125\n",
    "configBasicGauss[\"method\"] = 'simple'\n",
    "plannerFactory[\"BasicGauss_400\"] = [BasicGaussianPRM, configBasicGauss, IPVISBasicPRM.basicGaussPRMVisualize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultCollection (object):\n",
    "    \n",
    "    def __init__(self, plannerFactoryName, planner, benchmark, solution, perfDataFrame):\n",
    "        self.plannerFactoryName = plannerFactoryName\n",
    "        self.planner = planner\n",
    "        self.benchmark = benchmark\n",
    "        self.solution = solution\n",
    "        self.perfDataFrame = perfDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPTestSuite\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(IPTestSuite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for benchmark in IPTestSuite.benchList:\n",
    "    print(benchmark.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks durchführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultList = list()\n",
    "\n",
    "for key,producer in list(plannerFactory.items()):\n",
    "    print(key, producer)\n",
    "    for benchmark in IPTestSuite.benchList:\n",
    "        print (\"Planning: \" + key + \" - \" + benchmark.name)\n",
    "        #planner = IPBasicPRM.BasicPRM(benchmark.collisionChecker)\n",
    "        planner = producer[0](benchmark.collisionChecker)\n",
    "        IPPerfMonitor.clearData()\n",
    "        try:\n",
    "            \n",
    "            resultList.append(ResultCollection(key,\n",
    "                                            planner, \n",
    "                                            benchmark, \n",
    "                                            planner.planPath(benchmark.startList,benchmark.goalList,producer[1]),\n",
    "                                            IPPerfMonitor.dataFrame()\n",
    "                                            ),\n",
    "                        )\n",
    "        except Exception as e:\n",
    "            print (\"PLANNING ERROR ! PLANNING ERROR ! PLANNING ERROR \")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plannerFactory.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark-Grafiken plotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcdefaults()\n",
    "\n",
    "for result in resultList:\n",
    "    \n",
    "    fig_local = plt.figure(figsize=(20 ,20))\n",
    "    ax = fig_local.add_subplot(1,1,1)\n",
    "    title = result.plannerFactoryName + \" - \" + result.benchmark.name\n",
    "    if result.solution == []:\n",
    "        title += \" (No path found!)\"\n",
    "    title += \"\\n Assumed complexity level \" + str(result.benchmark.level)\n",
    "    ax.set_title(title)\n",
    "    try:\n",
    "        #IPVISBasicsPRM.basicPRMVisualize(result.planner, result.solution, ax=ax, nodeSize=100))\n",
    "        plannerFactory[result.plannerFactoryName][2](result.planner, result.solution, ax=ax, nodeSize=100)\n",
    "    except:\n",
    "        print(\"Exception\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark-Diagramme plotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8.0, 8.0]\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for bench in IPTestSuite.benchList:\n",
    "    title = bench.name\n",
    "    pathLength = dict()\n",
    "    planningTime = dict()\n",
    "    roadmapSize  = dict()\n",
    "    edgeLength = dict()\n",
    "    \n",
    "    for result in resultList:\n",
    "        if result.benchmark.name == bench.name:\n",
    "            #print result.benchmark.name  + \" - \" + result.plannerFactoryName, len(result.solution)\n",
    "            edgeLength[result.plannerFactoryName] = sum([euclidean(result.planner.graph.nodes()[current]['pos'], result.planner.graph.nodes()[previous]['pos']) for previous, current in zip(result.solution, result.solution[1:])])\n",
    "            pathLength[result.plannerFactoryName] = len(result.solution)\n",
    "            planningTime[result.plannerFactoryName] = result.perfDataFrame.groupby([\"name\"]).sum()[\"time\"][\"planPath\"]\n",
    "            roadmapSize[result.plannerFactoryName] = result.planner.graph.size()\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    width = 0.2\n",
    "\n",
    "    ax.bar(np.arange(len(pathLength.keys())), pathLength.values(),width, color=\"blue\")\n",
    "    ax.set_ylabel(title + \" Path length\", color=\"blue\")\n",
    "    ax.set_xticks(np.arange(len(pathLength.keys())) + width)\n",
    "    ax.set_xticklabels(pathLength.keys())\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    bar = ax2.bar(np.arange(len(pathLength.keys()))+width, planningTime.values(),width, color=\"red\")\n",
    "    ax2.set_ylabel(title + \" Planning time\", color=\"y\")\n",
    "\n",
    "    # Add coloring and patterns on axis two\n",
    "    hatches = ['x' if length==0 else '' for length in pathLength.values()]\n",
    "    color   = ['red' if length==0 else 'yellow' for length in pathLength.values()]\n",
    "    for i,thisbar in enumerate(bar.patches):\n",
    "        thisbar.set_facecolor(color[i])\n",
    "        thisbar.set_hatch(hatches[i])\n",
    "\n",
    "    # Multiple axes \n",
    "    ax3 = ax.twinx()\n",
    "    ax3.bar(np.arange(len(pathLength.keys()))+2*width, roadmapSize.values(),width, color=\"purple\")\n",
    "    ax3.set_ylabel(title + \" Roadmap size\",  color=\"purple\")\n",
    "    ax3.spines['right'].set_position(('axes', 1.15))\n",
    "    ax3.spines['right'].set_color(\"purple\")\n",
    "\n",
    "    ax4 = ax.twinx()\n",
    "    ax4.bar(np.arange(len(edgeLength.keys()))+3*width, edgeLength.values(),width, color=\"green\")\n",
    "    ax4.set_ylabel(title + \" Solution edge length\",  color=\"green\")\n",
    "    ax4.spines['right'].set_position(('axes', 1.30))\n",
    "    ax4.spines['right'].set_color(\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.perfDataFrame.groupby([\"name\"]).sum()[\"time\"]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a40cf6a1da29a39ead2ba32911a0c6fce94dd082a7ebb2950da7752aaf1c51d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
